{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bsPZQKgE3tX"
   },
   "source": [
    "## AIGCDetectBenchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/vohoaidanh/AIGDetection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZtRWDeMing8",
    "outputId": "5d83d40e-05ac-4bbe-a5b5-29ea56eaaca5"
   },
   "outputs": [],
   "source": [
    "!pip install ftfy -q\n",
    "!pip install natsort -q\n",
    "!pip install blobfile -q\n",
    "#!pip install mpi4py -q\n",
    "!pip install comet_ml -q\n",
    "!pip install grad-cam -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorboardX -q\n",
    "!apt-get install -y unzip -q\n",
    "!apt-get install -y zip -q\n",
    "!pip install regex -q\n",
    "!pip install imageio -q\n",
    "!pip install opencv-python -q\n",
    "!apt-get install -y libgl1-mesa-glx -q\n",
    "!pip install scikit-learn -q\n",
    "!pip install scikit-image -q\n",
    "!pip install gdown -q\n",
    "!pip install pickleshare -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9HXSjhchADX",
    "outputId": "e7c10e63-1b0e-4c5f-8ea6-cdc24bd92a72"
   },
   "outputs": [],
   "source": [
    "%cd /workspace/AIGDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-fusion-2024_07_09_08_02_39\n"
     ]
    }
   ],
   "source": [
    "!ls  checkpoints\n",
    "!rm -r checkpoints/model-fusion-2024_07_09_08_02_39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                     arch: res50                         \n",
      "               batch_size: 32                            \t[default: 64]\n",
      "                    beta1: 0.9                           \n",
      "                blur_prob: 0                             \n",
      "                 blur_sig: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                class_bal: False                         \n",
      "                  classes: car,cat,chair,horse           \t[default: ]\n",
      "           continue_train: False                         \n",
      "                 cropSize: 224                           \n",
      "                 data_aug: False                         \n",
      "                 dataroot: /workspace/datasets/ForenSynths_train_val\t[default: ./dataset/]\n",
      "                delr_freq: 10                            \t[default: 20]\n",
      "            detect_method: model_fusion                  \t[default: NPR]\n",
      "          earlystop_epoch: 15                            \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               jpg_method: cv2                           \n",
      "                 jpg_prob: 0                             \n",
      "                 jpg_qual: 75                            \n",
      "               last_epoch: -1                            \n",
      "                 loadSize: 256                           \n",
      "                  loss_fn: BCEWithLogitsLoss             \n",
      "                loss_freq: 400                           \n",
      "                       lr: 0.0002                        \t[default: 0.0001]\n",
      "                     mode: binary                        \n",
      "                     name: model-fusion-2024_07_09_08_04_19\t[default: experiment_name]\n",
      "                new_optim: False                         \n",
      "                    niter: 1000                          \n",
      "                  no_flip: False                         \n",
      "              num_threads: 4                             \t[default: 8]\n",
      "                    optim: adam                          \n",
      "           resize_or_crop: scale_and_crop                \n",
      "                rz_interp: bilinear                      \n",
      "          save_epoch_freq: 20                            \n",
      "         save_latest_freq: 2000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "              train_split: train                         \n",
      "                val_split: val                           \n",
      "----------------- End -------------------\n",
      "train.py  --name  model-fusion-  --dataroot  /workspace/datasets/ForenSynths_train_val  --detect_method  model_fusion  --num_thread  4  --classes  car,cat,chair,horse  --batch_size  32  --delr_freq  10  --lr  0.0002  --niter  1000\n",
      "Detect method model model_fusion\n",
      "load model_A weight: /workspace/AIGDetection/model_epoch_last_3090.pth\n",
      "load model_B weight: /workspace/AIGDetection/Gaussblur-4class-resnet-car-cat-chair-horse2024_06_20_08_12_39_model_eopch_7_best.pth\n",
      "cwd: /workspace/AIGDetection\n",
      "2024_07_09_08_05_01 Train loss: 0.00014556200767401606 at step: 400 lr 0.0002\n",
      "2024_07_09_08_05_42 Train loss: 7.46837213227991e-06 at step: 800 lr 0.0002\n",
      "2024_07_09_08_06_23 Train loss: 3.091982705427654e-07 at step: 1200 lr 0.0002\n",
      "2024_07_09_08_07_04 Train loss: 1.6264466466964222e-05 at step: 1600 lr 0.0002\n",
      "2024_07_09_08_07_44 Train loss: 5.587889404523594e-07 at step: 2000 lr 0.0002\n",
      "2024_07_09_08_08_25 Train loss: 1.7024112821673043e-06 at step: 2400 lr 0.0002\n",
      "2024_07_09_08_09_06 Train loss: 9.840927305049263e-06 at step: 2800 lr 0.0002\n",
      "2024_07_09_08_09_46 Train loss: 3.695274244819302e-06 at step: 3200 lr 0.0002\n",
      "2024_07_09_08_10_27 Train loss: 1.1264403838140424e-05 at step: 3600 lr 0.0002\n",
      "2024_07_09_08_11_08 Train loss: 0.0 at step: 4000 lr 0.0002\n",
      "2024_07_09_08_11_48 Train loss: 0.0 at step: 4400 lr 0.0002\n",
      "(Val @ epoch 0) acc: 1.0; ap: 1.0\n",
      "acc increate 0 --> 1.0, saving best model\n",
      "Saving model ./checkpoints/model-fusion-2024_07_09_08_04_19/model_epoch_0_best.pth\n",
      "early_stop_count = 0/7\n",
      "2024_07_09_08_12_35 Train loss: 8.828813520267431e-07 at step: 4800 lr 0.0002\n",
      "2024_07_09_08_13_16 Train loss: 0.0 at step: 5200 lr 0.0002\n",
      "2024_07_09_08_13_57 Train loss: 0.0 at step: 5600 lr 0.0002\n",
      "2024_07_09_08_14_38 Train loss: 0.0 at step: 6000 lr 0.0002\n",
      "2024_07_09_08_15_19 Train loss: 0.0 at step: 6400 lr 0.0002\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/AIGDetection/train.py\", line 94, in <module>\n",
      "    model.optimize_parameters()\n",
      "  File \"/workspace/AIGDetection/networks/trainer.py\", line 66, in optimize_parameters\n",
      "    self.forward()\n",
      "  File \"/workspace/AIGDetection/networks/trainer.py\", line 60, in forward\n",
      "    self.output = self.model(self.input)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/workspace/AIGDetection/networks/resnet_fusion.py\", line 75, in forward\n",
      "    feat_B = self.model_B(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/workspace/AIGDetection/networks/resnet_local_grad.py\", line 170, in forward\n",
      "    x = self.layer2(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/workspace/AIGDetection/networks/resnet_local_grad.py\", line 80, in forward\n",
      "    out = self.conv1(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#experiment-01-no-filter\n",
    "!find /workspace/datasets -type d -name \"*ipynb*\" -exec rm -r {} +\n",
    "!python train.py \\\n",
    "--name model-fusion- \\\n",
    "--dataroot /workspace/datasets/ForenSynths_train_val \\\n",
    "--detect_method model_fusion \\\n",
    "--num_thread 4 \\\n",
    "--classes car,cat,chair,horse --batch_size 32 --delr_freq 10 --lr 0.0002 --niter 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls checkpoints/experiment-01-fft-lowpass-2024_07_08_02_24_45/*.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_path checkpoints/model-fusion-2024_07_09_08_04_19/model_epoch_0_best.pth\n",
      "Detect method model model_fusion\n",
      "load model_A weight: /workspace/AIGDetection/model_epoch_last_3090.pth\n",
      "load model_B weight: /workspace/AIGDetection/Gaussblur-4class-resnet-car-cat-chair-horse2024_06_20_08_12_39_model_eopch_7_best.pth\n",
      "=================================\n",
      "           ForenSynths\n",
      "=================================\n",
      "2024_07_09_08_22_11\n",
      "(0 biggan      ) acc: 86.9; ap: 92.5\n",
      "(1 crn         ) acc: 50.0; ap: 50.6\n",
      "(2 cyclegan    ) acc: 97.0; ap: 98.8\n",
      "(3 deepfake    ) acc: 72.2; ap: 93.7\n",
      "(4 gaugan      ) acc: 83.2; ap: 85.6\n",
      "(5 imle        ) acc: 50.0; ap: 50.6\n",
      "(6 progan      ) acc: 99.9; ap: 100.0\n",
      "(7 san         ) acc: 66.0; ap: 72.4\n",
      "(8 seeingdark  ) acc: 56.4; ap: 62.5\n",
      "(9 stargan     ) acc: 100.0; ap: 100.0\n",
      "(10 stylegan    ) acc: 96.7; ap: 100.0\n",
      "(11 stylegan2   ) acc: 98.7; ap: 100.0\n",
      "(12 whichfaceisreal) acc: 67.5; ap: 78.0\n",
      "(13 Mean      ) acc: 78.8; ap: 83.4\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "#Gradient full resnet test\n",
    "!find /workspace/datasets -type d -name \"*ipynb*\" -exec rm -r {} +\n",
    "model_path = \"checkpoints/model-fusion-2024_07_09_08_04_19/model_epoch_0_best.pth\"\n",
    "!python test.py \\\n",
    "--model_path $model_path --batch_size 32 \\\n",
    "--num_thread 2 \\\n",
    "--detect_method model_fusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "#https://drive.google.com/file/d/1ytZBMhTWZ6pGrrzID2a7mPASLKOWGhri/view?usp=drive_link\n",
    "#https://drive.google.com/file/d/1xHhCcCWtv57tnlAKh5sLSofuzcZcFfsP/view?usp=drive_link\n",
    "file_id = '1xHhCcCWtv57tnlAKh5sLSofuzcZcFfsP'\n",
    "destination = '/workspace/Progan_val.zip'  # Desired file name and extension\n",
    "\n",
    "# Construct the download URL\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, destination, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/model-fusion-2024_07_09_08_04_19/model_epoch_0_best.pth\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/*/*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find checkpoints/experiment-01-fft-highpass-r70-2024_07_08_05_36_56 -type f -name \"*.pth\" -not -name \"model_epoch_22_best.pth\" -exec rm {} +\n",
    "#checkpoints/experiment-01-fft-lowpass-2024_07_08_02_24_45/model_epoch_17_best.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp checkpoints/model-fusion-2024_07_09_08_04_19/model_epoch_0_best.pth -d /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
